



# MySQL中1000万条数据你是怎么查询的？查询非常慢如何优化?

相同偏移量，不同数据量：

![image-20230522121148606](C:\Users\李凯\AppData\Roaming\Typora\typora-user-images\image-20230522121148606.png)

不同偏移量，相同数据量：

![image-20230522121415760](C:\Users\李凯\AppData\Roaming\Typora\typora-user-images\image-20230522121415760.png)



### 针对数据量大的情况，我们可以做以下优化：

1、按需查找字段，减少网络IO消耗

2、避免使用select * ,减少mysql优化器的负担（select* 需要把 * 转化为所有字段，当并发量大的情况下，会增加优化器的负担）

3、查询字段尽量保证索引覆盖

4、借助nosql缓存数据缓解mysql数据库的压力

### 偏移量大的优化方案

偏移量大的情况下我们也可以使用数据量大的优化方案，除此之外还可以将偏移量修改为id限定的方式提升查询效率

```mysql
select * from user limit 1000000,100;
```

d限定的方式提升查询效率：

```mysql
select * from user where id > 1000000 limit 100;
```

## 服务端对客户端进程发的请求做的处理：

客户端 ----> 处理连接 ----> 查询缓存（命中率很低） ----> 语法解析 ----> 查询优化 ----> 存储引擎 ----> 文件系统

## 为什么 MySQL 喜欢 B+ 树？

MySQL 是会将数据持久化在硬盘，而存储功能是由 MySQL 存储引擎实现的，所以讨论 MySQL 使用哪种数据结构作为索引，实际上是在讨论存储引使用哪种数据结构作为索引，InnoDB 是 MySQL 默认的存储引擎，它就是采用了 B+ 树作为索引的数据结构。

要设计一个 MySQL 的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I/0 的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I/0 的操作次数内完成。

二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。

为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。

而树的高度决定于磁盘  I/O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。

B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

## 聊聊索引失效？失效的原因是什么？

https://bbs.huaweicloud.com/blogs/333163

# MYSQL的RR隔离级别是如何解决幻读的

[MYSQL的RR隔离级别是如何解决幻读的_隔离级别为rr时，关于幻读_之诚的博客-CSDN博客](https://blog.csdn.net/leisurelen/article/details/108436815)



# 参考笔记

[learn_db/mysql/learn_mysql_ksf at master · lliuql/learn_db · GitHub](https://github.com/lliuql/learn_db/tree/master/mysql/learn_mysql_ksf)

# MySql重点知识整理

## MySql逻辑架构：连接层、服务层、引擎层

- 连接层：主要用来处理客户端的连接请求，权限管理等，使用了线程池来对客户端请求分配线程。
- 服务层：由SQL接口、解析器、优化器、查询缓存（MySQL8移除）组成
  - SQL接口：用来接收sql语句，并获取sql的执行结果返回给客户端
  - 解析器：对sql语句进行词法语法解析，并生成语法解析树
  - 优化器：查询到一个最佳的sql执行计划，如是使用全表扫描还是通过索引查询，若索引有多个的话选择哪一个最优等优化
- 引擎层：真正的对物理磁盘的数据的查询和更新，并且MySql的存储引擎是插件式的，可以根据不同场景选取不同的存储引擎，像innodb,MyISAM等

sql执行流程：接收到一条sql语句时，在5.7版本中会先在查询缓存中进行查询，若是命中的话直接返回缓存中的数据，但查询缓存在8.0版本中因为命中率太低被移除了。之后会有解析器进行词法语法的解析并生成语法解析树，再由优化器生成一个最佳的执行计划，最后由存储引擎来在磁盘文件中执行查询。

sql语句执行流程：from -> on (join condition) -> where -> group by -> having by -> select -> distinct -> order by -> limit

## 缓冲池

​	我们直到MySQL中的数据是存在物理磁盘中的，并且不是连续存储的，如果我们每次的查询都要从磁盘中查找的话，大量的随机IO会很大的降低我们的查询效率，随意就提出了缓冲池（buffer pool）的概念，在InnoDB引擎中，数据的交换是以数据页为单位的，在每次的磁盘IO 后，InnoDB会将此次读取到的整个数据页中的数据缓存在缓冲池中，下次查询或更新时优先在缓冲池中查询，降低了磁盘IO次数。缓冲池中的数据也并不是每次更新后会立即刷新磁盘，而是一一定频率刷盘。

​	在MySQL服务器启动时，我们一般会进行预读，将一些热点提前缓存在缓冲池中。

## InnoDB和MyISAM对比

- InnoDB支持外键、事务，MyISAM不支持
- InnoDB支持行级锁，MyISAM只支持表级锁，在并发环境下MyISAM的表现很差
- MyISAM没有聚簇索引，所有的索引都是二级索引，索引的叶子节点中存放的时每条记录的地址值，所以MyISAM不需要回表，直接根据地址值访问数据页
- MyISAM缓存之缓存索引，不缓存数据，InnoDB索引数据都要缓存，对内存要求高
- 磁盘文件存储的格式也不一样，MyISAM索引和文件分开存储，索引存在.MYI文件中，数据存在.MYD文件中，InnoDB数据和文件存储在一起，在.ibd文件中

## InnoDB索引结构：B+树

总体上来说：B+树，所有的数据存放在叶子节点中，非叶子节点存放的是索引数据。并且叶子节点和非叶子节点之间之间都用双向链表链接。

从一个数据页来说，数据页也就是B+树的节点，为了实现对一个数据页中的数据实现快速查找，B+树在每个数据页中对数据进行排序，这样就可以利用二分法进行快速查找，同时为了避免在数据页中插入删除数据时发生数据的移动，发生页分裂带来的开销，数据页内部的每条记录之间离散存储，每条记录之间用单向链表进行连接。

为了快速定位到查询的数据所在的数据页，就像上抽取出了索引页，索引页中记录了每个孩子数据页中最小的字段值，以及指向该数据页的指针，如果时二级索引的话，为了保证索引节点中每条记录的唯一性，在每条记录中还要保存对应的主键。索引页中也维护了页目录，通过页目录在索引页中也可以通过二分法快速定位下层的索引页或是数据页。

以上就是B+数据整体结构

问题：

- 为什么叶子节点之间要通过双向链表连接呢？
  - 为了方便范围查找，范围查找时是需要找到临界值，然后在叶子节点进行遍历，也方便order by和group by，不用再重新对字段进行排序

- 为什么使用B+树作为InnoDB的索引结构？
  - hash
    - hash结构虽然能实现一次磁盘IO就读取到对饮的数据页，但是仅限于等值判断，对于范围查找还是要一个一个找，磁盘IO就会将为O(N)
    - 若字段中有大量重复的值，这时就会造成大量的hash碰撞，需要对对应桶位中的记录进行O(N)或O(logn)的查询
    - 也无法优化order by和group by
    - hash索引也不能对联合索引进行最左匹配原则，因为hash的联合索引是对联合字段整体求一个hash值
  - 二叉搜索树
    - 二叉搜索树且不说只有两个分支，极端情况下若是字段值都是按序排列，那么索引将退化为链表
  - AVL树
    - AVL树虽然解决的二叉搜索树退化为链表的问题，但本质还是二叉的
  - B树
    - B树相比于B+树，它不仅叶子节点可以存放数据，非叶子节点也可以存放数据，这一点导致了B树的叶子节点中的索引记录少于B+树，因为B+书叶子节点不存放数据，只存放字段值，所以所B+树再数据页大小相等的情况下比B树更加矮胖，磁盘IO更少
    - 由于B+树非叶子节点不存放数据，所有的数据一定是在叶子节点中查询到，查询效率更为稳定。
    - B树节点之间并没有用双向链表进行连接，所以范围查询时只能对B树进行中序遍历进行查询。

## 日志

**redo log**

​	说redo log 的话，就不得不说缓冲池buffer poor了，MySQL他的数据是存储在磁盘文件中的，每次对数据的增删改查如果都从磁盘访问的话，效率会很低，所以InnoDB引入了Buffer poorL避免大量的磁盘IO，在访问磁盘数据的时候先从磁盘中把数据对应的数据页加载到缓冲池中，对缓冲池的数据进行操作，而缓冲池中的数据并不是实时刷新到磁盘中的，而是由master线程隔一段时间进行刷盘，但在这一段时间内数据库宕机或其他原因，会造成缓冲池的数据没有同步到磁盘中，而redo log 就是解决这个问题，通过WAL技术，先写日志，再刷磁盘来保证事务的持久性。

​	redo log 具体是怎么工作的呢？在sql语句对缓冲池中的数据做了修改以后，会将此次的修改记录到redo日志中，redo日志他是记录物理级别的对数据页的修改，比如在某数据页的某偏移量出插入了什么数据，在MySQL服务器重启时，会根据redo日志中的记录对数据做恢复。

​	虽然redo日志它是顺序记录在磁盘文件中的，但是频繁的刷盘还是会降低效率，所以参考buffer poor，又引入了redo log buffer，在对缓冲池中的数据修改后，不直接记录日志，先把修改操作记录到redo log buffer中，在对redo log buffer 采取刷盘策略来对其进行redo log buffer 的刷盘。这又涉及到了redo log buffer 的三种刷盘策略：

- 0：每次写入redo log buffer 后，不主动的进行任何刷盘操作，交给后台的master线程来进行刷盘，master线程会每个一秒进行一次刷盘。这种刷盘策略效率最高，但有可能会导致一秒的数据不同步
- 1：每次写入redo log buffer后，立即执行刷盘，这也是MySQL的默认值。这种最安全，但相比之下效率不如其他两种
- 2：每次写入redo log buffer后，会将buffer中的数据写到操作系统的page cache（文件系统缓存）中，置于page cache中的数据什么时候刷到磁盘文件中，就交给操作系统决定。也算是0和1的这种方案

​	随着日志的不断记录，我们还要对redo 日志做一些清理或重用，也就是checkpoint机制，将一些已经刷盘过的数据区域进行重用。

**undo log**

​	在事务未提交之前，代码发生异常或是数据库宕机，这时为了保证事务的原子性，需要对事务中已经执行的语句进行回滚，而这个回滚就是用undo log来实现的。

​	undo log 它在sql语句执行之前记录undo 日志，但它不同于redo，它是逻辑级别的日志，比如在执行一条insert 语句之前，他会记录对应的delete语句，回滚时根据行记录的隐藏字段回滚指针找到undo 日志进行回复即可。

​	实现事务的回滚时undo log的功能之一，还有就是MVCC的实现也是借助undo log 的update 类型的undo log在实现对统一数据的旧版本的读取，也正因为如此，所以update undo log在十五提交之后并不会立刻删除，而insert undo log 在事务提交之后会立刻删除。

​	undo日志和redo 一样，也会对其进行重用。每个事务申请一个undo页后，有时候并不能完全使用，这就导致了一部分空间的浪费，所以若是一个undo 页的使用不超过四分之三时，其他事务也可以在这个undo 页上接着记录日志。

**binlog**

binlog它是逻辑日志，会将DML,DDL语句记录到binlog中，主要用于数据的恢复和主从复制，有三种格式，statement，row，Mixed混合模式。

- statement记录的是每条DDL、DML语句，不需要记录每一行记录的变化，相对row来说，binlog文件大小会小很多
- row格式它会记录每一行的数据变化，尤其是像带条件的DML语句，一条语句可能会导致大量的行记录被修改，修改频繁的话会binlog文件很快会被写满
- mixed混合模式，混合使用statement和row模式

binlog写入磁盘时和redo log 很像，也是先写缓存再刷盘，只不过binlog要保证一个事务的binlog不能被拆开，所以会为每一个线程单独开辟一个binlog cache空间，我们也可以设置不同的参数来实现不同的刷盘策略：

- 参数设置为0，表示每次事务提交时binlog cache中的数据刷到操作系统中的page cache中
- 参数为1的话，就是每次事务提交时会将cache中的数据刷新到磁盘文件中
- 参数为N是一种折中方案，先将cache中的数据刷到page cache中，当page cache中累计了N个事务后再将page cache中的数据进行刷盘

由于binlog和redo log 的刷盘时机可能出现不一致，redo log它并不一定会在事务提交时进行刷盘，具体这里先不说了，这就导致了可能会出现redo log 刷盘成功了，但在binlog 刷盘时出现故障，刷盘失败，binlog中少记录了这条事务的操作记录，在利用binlog进行数据恢复或主从复制时，数据和原库中的数据不一致的问题 。针对这个问题，有采取了redo log 的两阶段提交方案。

- 将redo log 的写入拆分为两个阶段，prepare阶段和commit阶段。当redo log进行写入磁盘时，先进入prepare 阶段，直到binlog执行完写入后，再进行redol log 的commit阶段。在进行数据恢复时，检查redo log处于哪个阶段，若是处理prepare阶段，说明binlog中并没有记录这条事务，就会对该事务进行回滚；如果处于commit阶段，说明binlog和redo log都已经写入了，直接进行数据恢复就行。

> redo log 在事务提交之前会持久化到磁盘中吗?
>
> ​	会
>
> - 如果redo log的刷盘策略设置为0的话，将会由后台线程每个一秒对redo log buffer 中数据进行一次刷盘，也许在这个过程中事务正在进行中还没提交
> - 还有就是其他事务结束进行，对redo log buffer 进行刷盘时，由于redo log buffer 并不像binlog 那样为每个线程分派一个cache，而是多个线程共用一个buffer,当其他事务进行redo log 的写入时，数据页中可能会有其他事务的redo 日志。
> - 还有当redo log buffer 的占用到某个阈值时，就会由后台线程对redo log buffer 进行刷盘，也可能回到之redo log 在事务提交之前持久化到磁盘



## 锁

​	MySQL的脏读脏写都是通过锁机制来实现的，我们可以手动加锁（lock in share mode、for update）来实现，不手动加锁的话MySQL会加入隐式锁，通过事务id这个隐藏字段来判断最近操作这条数据的事务是否活跃来决定是否将隐式锁变为显式锁。

- 按数据操作的类型划分：读锁、写锁（共享锁（S）、排他锁（X））

  - 排他锁和排他锁之间、共享锁之间都是不兼容的，也就是写写互斥、读写互斥
  - 共享锁和共享锁之间是兼容的，和排他锁之间是互斥的，读读是共享的

- 按锁的粒度来分：行级锁、表级锁、页级锁

  - 行级锁

    - 记录锁：针对某一条记录加锁

    - 间隙锁：在RR隔离级别下，通过锁住某一个间隙，来解决幻读问题

      - 比如我要根据某张表中的主键id来查询，这张表中的主键它并不连续，假如是

        1、3、8这样，在同一个事务中，我要查询id = 5的话，会在（3，8）这个间隙中

        查询间隙锁，锁住这个间隙，当有其他事务想要在这个间隙中插入数据的话，就会

        阻塞，但是有一种情况就是，加入id为8的数据是最后一条记录，由于间隙锁只会锁住当前记录之前的间隙，所以8之后的间隙也就是（8，+∞）这个间隙如何锁住呢？其实在在每个数据页中都有额外记录俩条记录，分别表示当前数据页中的最小记录和最大记录，通过给最大记录加锁来锁住（8，+∞）这个间隙。

    - 临建锁：其实就是记录锁+间隙锁。因为间隙锁锁住的区间是开区间，有时我们想既锁住这条记录又想锁住这条记录前面的间隙，这时候就用临建锁

  - 表级锁

    - 意向锁：我们想要对整个表加表锁的话，如果没有意向锁，那么我们就要遍历每一条记录来检查是否有行锁存在，而有了意向锁的话，我们对某条记录加了行锁，数据库会自动对该表加上对应的意向锁，那么我们就不需要遍历整张表来检查行锁，而是在加表锁的时候通过判断该表是否加了意向锁。
      - 意向锁他不会影响并发性，他不会与行级共享锁和排他锁互斥

  - 元数据锁

    - 元数据锁它是用来保证对该表做增删改查时表的结构不会发生改变

- 从对待所得态度来分：乐观锁和悲观锁

  - 乐观锁
    - 乐观锁它并不会具体的一种锁，认为该记录不会总是被并发访问到，属于小概率事件，不用每次都对记录加锁，但是在对该记录进行更新时会判断在此期间有没有别的事务修改过。通常用版本号、或是时间戳机制来实现，通常用于读多写少的场景。像InnoDB实现的MVCC，并发工具StampedLock都是体现了乐观锁的思想。
  - 悲观锁
    - 每次对记录的访问都会加锁，适合写多读少的场景

- 还有显示锁和隐式锁：

  - 显示锁：手动加锁 lock in share mode、for update就是显示锁
  - 隐式锁：如果我们不手动加锁，像事务A要在表中update一条记录，不显式的加锁，此时事务B要获取给记录的共享锁或排他锁，此时事务B会检查根据这条记录的事务id检查当前事务是否活跃，若是活跃的话，这时候会将隐式锁转化为显示锁。

## MVCC

MVCC，也就是多版本并发控制，通过记录数据的多个版本来实现数据库的一致性读，只不过它是基于快照读，所以并不能像加锁那样保证数据强一致性，而是弱一致性读。

MVCC 它的实现主要有行记录的事务id、回滚指针这两个隐藏字段、undo log版本链、ReadView这三部分。

- 隐藏字段和版本链
  - 事务id表示对当前记录修改的事务的id，回滚指针指向的就是 update 类型 undo log ，其中的多版本也就是基于 undo log 版本链来实现的。
- ReadView
  - ReadView就是在事务进行快照读的时候生成的一个读视图。里面记录当前活跃事务的id。
  - ReadView 中主要有4个重要的内容
    - 创建当前ReadView的事务id
    - 当前活跃的事务链表
    - 活跃事务中最小的事务id
    - 当前系统应该分配给下一个事务的id值
  - 当进行读取某条记录时，会将行记录中的事务id和ReadView 中记录的事务 id 进行对比
    - 如果行记录中的事务id 等于create_id，这条记录就可以直接读取，相当于在同一个事务内做的修改
    - 如果行记录的事务id 小于ReadView中的最小id，也可以读取，如果比最小的还小，说明行记录中的事务已经提交了
    - 如果行记录的事务id 大于等于ReadView 中预分配的事务id，就不可以获取整个行记录，需要通过回滚指针找之前的版本
    - 如果行记录中的事务id大于ReadView中最小的id，有小于ReadView 中预分配的id，就判断是否在活跃事务链表中，在的话不可读，不在的话可以读

MVCC 通过这种快照读的机制不仅实现了读读并发，有实现了读写并发，提高了系统的并发性能，虽然牺牲了强一致性，但高并发和一致性它俩天生就是矛盾的，我们在实现时也只能折中处理。像java中的一些并发工具，CopyOnWriteArrayList之类的也是牺牲了读的强一致性来提高并发性。

MVCC解决用来实现MySQL中的RC和RR这两个隔离级别，RC解决了脏读，RR既解决了不可重复读，又解决了幻读的问题                                                                                                                                                                                                                        

> mvcc只能解决读写、写读问题，MySQL对写写冲突还是通过锁来解决的
>
> MVCC为什么不需要insert undo log，只需要update undo log?
>
> 因为insert 操作没有旧版本，当前版本就是最新的，MVCC它是通过undo log 版本链，使得读操作可以读到旧版本的数据，insert的数据没有旧版本，因此也就没有必要用到insert undo log，需要update undo log是因为我们要通过它来获取某条数据的旧版本。

## 主从复制

主从复制的作用：

- 读写分离：通过master和slave实现读写分离，提高了数据库的并发性。
  - 为什么说读写分离提高了数据库的并发性呢？
    - 首先通过读写分离，降低了单个数据库的访问压力，并且我们可以对读库进行负载均衡，将多个读请求按照某种策略均匀的分发到不同的从库上，避免出现请求倾斜的问题
    - 还有就是避免了万一出现了锁表的情况，导致所有的请求都需要阻塞的问题，读写分离后，主库锁表后，并不会影响到从库的读请求
- 用于数据备份
- 实现了系统的高可用：当主库发生宕机等异常时，可以再从库中选举中一个来充当新的主库进行工作。

主从复制的原理：主要有三个线程和两个日志完成

- 当binlog发生更新时， 主库的会创建log dump线程（二进制转储线程），通知从库，并且读取binlog中的数据发送到从库中，log dump再 读取binlog的时候，会对binlog加锁
- 从库会创建IO线程来接受主库法老的binlog日志，并将其存储到从库的中继日志中
- 从库的sql线程会去读取中继日志中的数据对从库数据进行同步

主从复制导致的数据一致性问题：

​	主库的更新数据同步到从库的延时问题

​	主从复制的模式：异步复制、半同步复制、组复制

​	MySQL默认采用的异步复制来实现主从数据一致性

- ​	异步复制：主库将更新的数据发送搭配从库后，并不关心从库时候正确接受，主库不会进行阻塞等待，而是继续工作，异步复制几乎不存在主从复制的延时，但是并不能保证主从之间数据的一致性
- ​	半同步复制：主库将更新数据发送给从库后，会进入阻塞，等到至少一个从库发来接受确认才继续进行工作，相比于异步复制增加了延时，但也提高了数据一致性
- ​	组复制：





 
