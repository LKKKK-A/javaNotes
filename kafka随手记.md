## 服务器宕机了，Kafka 消息会丢失吗？

https://cloud.tencent.com/developer/article/2100063

### **生产者发送数据丢失**

原因：由于网络原因数据在发送的过程中丢失或者数据还没有持久化到磁盘，服务器宕机导致数据丢失。

Acks确认机制：

​	ack = 0：生产者发送数据后不等Leader确认回复就继续发送数据，吞吐量最好，但很容易发生数据丢失

​	ack = 1：生产者发送数据后等待leader的确认回复后就继续发送数据，不等其他副本的回复，这样相比于0来说虽然降低了数据丢失的可能性，但若是leader副本所在的broker宕机了，那么新的leader中可能没有从leader中成功拉取到，导致数据的丢失。

​	ack = -1：生产者发送数据后必须等到leader和ISR队列中的所有副本的确认回复后才发送下一个数据。但若是某主题的partition只有一个副本的话，那么就和ack = 1一样了，所以说，在ack = -1 的级别下，要保证数据不丢失，那么至少partition要有两个副本，并且ISR队列中的副本数至少也要两个。

### 生产者发送数据重复

原因：1、在ack = -1的级别下，leader节点将内存中的数据进行刷盘后，在回复ackq确认的时候leader所在的节点宕机了，这时新的leader上线，生产者收不到leader的ack确认，就会重发数据，而新的leader中有该数据，所以导致了数据的重复。

解决：利用幂等性和事务

幂等性：就是用PID（生产者ID）、分区号、sequence number（序列号）来唯一标识一条数据，PID他在同一个会话内唯一的，序列号是一个递增序列，每个partition中都有一个递增的序列号。当leader收到数据后，回通过这三者来判断数据是否已经发送过，如果已经发送过，那么就不会对这条数据进行持久化。

幂等性它并不能完全保证数据不重复，比如生产者如果在对数据进行分区时采用的是轮询分区器，那么在进行重发的时候，同一个数据两次的分区可能不一样，这样的话，数据就会被重复的持久化；也有可能leader宕机了，重启后PID也会被重新分配。

对于这些问题导致的数据重复，就只能用事务来解决了。kafka事务它也是借助幂等性来实现的。

当生产者发送的一批数据中，有一个出现了问题，就会对事务进行回滚，来保证出现问题后数据不会持久化到磁盘。

### 生产者发送数据乱序

每隔broker节点中最多可以缓存5个生产者请求，若是前面的请求发送失败重发，重复就会导致前面的请求乱序到达。

解决：kafka没引入幂等性之前要保证单分区有序的话，只能将broker节点中的缓存请求数量设置位1

引入幂等性之后，最大可以将缓存数量设置为5：因为我们可以通过序列号来保证单分区内有序，比如有5批数据，第一批和第二批按需到达，这时我们就可能对12批的数据落盘，但第三批数据进行了重发，第四批数据先于第三批数据到达，此时不会对第四批数据进行落盘，而是等第三批数据到达以后，重新对数据进行排序后才进行落盘，这样就保证了单分区有序

